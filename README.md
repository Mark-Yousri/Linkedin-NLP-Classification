# Linkedin-NLP-Classification

This notebook is a data analysis project that aims to explore the characteristics and trends of job postings on LinkedIn, a popular professional networking platform. The notebook uses various Python libraries and tools, such as pandas, numpy, seaborn, matplotlib, texthero, nltk, gensim, scikit-learn, xgboost, and transformers, to perform data cleaning, preprocessing, visualization, feature engineering, and modeling tasks.

The main objectives of this project are:

- To understand the distribution and composition of job postings on LinkedIn by different attributes, such as location, industry, function, employment type, etc.
- To identify the most common and important skills, requirements, and keywords for different job roles and sectors.
- To build and compare different machine learning models, such as logistic regression, support vector machine, decision tree, AdaBoost, multilayer perceptron, and XGBoost, to classify job postings as fake or real based on their content.

The notebook consists of the following sections:

- Importing libraries and packages
- Loading and exploring the data
- Data cleaning and preprocessing
- Data visualization and analysis
- Feature engineering and transformation
- Model training and evaluation
- Saving and loading models

The data used in this project is a CSV file containing 12841 job postings scraped from LinkedIn. The data has 17 columns, including job title, office location, company information, job description, job requirements, benefits, telecommuting, company logo, has questions, employment type, education required, industry, function, and fake. The fake column indicates whether the job posting is fraudulent or not, with 1 for fake and 0 for real.

The notebook is intended for anyone who is interested in data science, machine learning, natural language processing, or job market analysis. The notebook can be run on Google Colab or any other Jupyter-compatible environment. The notebook requires Python 3.10 or higher and the installation of the libraries and packages listed in the first section. The data file can be downloaded from the link provided in the second section.
